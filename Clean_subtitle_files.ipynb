{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8067fb7-1f7e-430c-bfa1-da9187334a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b8713e-c681-4700-9d1b-ea89f3f45321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to chunk a given file in list form into 4 parts\n",
    "def chunkin(f):\n",
    "    chunk=[]\n",
    "    #count the number of '' in a list and divide by 4\n",
    "    #round it off\n",
    "    find_index= round(f.count('')/4)\n",
    "    #since rounding off will offset the slicing of the fourth in the coming steps, preserve the 3rd multiple \n",
    "    last_chunk = find_index*3\n",
    "    #c is going to keep the count of '' in the list f\n",
    "    c=0\n",
    "    #j takes the value of i in later steps\n",
    "    j=0\n",
    "    #keeps the total count of '', similar to c but has a different function\n",
    "    total_count=0\n",
    "    #indexing all the elements in the list f\n",
    "    for i in range(len(f)):\n",
    "        #taking into account '' strings condition \n",
    "        if f[i] == '':\n",
    "            #adds 1 to c\n",
    "            c+=1\n",
    "            #adds 1 to total_count\n",
    "            total_count+=1\n",
    "            #if c is equal to find_index (the 1/4th count of '' in the list f)\n",
    "            if c == find_index:\n",
    "                #bringing c back to 0 for the next round\n",
    "                c=0\n",
    "                #slicing the list into one part (the first time from [0:i], j=0) and appending to a list called 'chunk'\n",
    "                chunk.append(f[j:i])\n",
    "                #now assigning j with value of i\n",
    "                j=i\n",
    "                #this goes on for 2 more rounds where when c==find_index, the list is sliced further\n",
    "                #but since the last chunck just needs the 3rd multiple as its starting point...\n",
    "                #4th chunk checks if total_count has reached the last_chunk number to use the index j (since i is now assigned to j)\n",
    "                #to  make the last slice\n",
    "                if total_count==last_chunk:\n",
    "                    #append last chunck to 'chunk'\n",
    "                    chunk.append(f[j:])\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944e1761-c6f0-42f6-88ee-afc1108787c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove all empty strings from a list of strings\n",
    "def half_clean(sub):\n",
    "    sub_clean = []\n",
    "    #taking chunk by chunk\n",
    "    for x in sub:\n",
    "        #considering elements that are not '' strings\n",
    "        no_empty=[i for i in x if i]\n",
    "        #appending list to a new list called 'sub_clean'\n",
    "        sub_clean.append(no_empty)\n",
    "    return sub_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45b10a9-a0f2-4804-908a-3dc323bb7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to remove all the time stamps and numberings that come before it to make a clean list (chunk) of strings.\n",
    "#since the lists are chunks we need to preserve them together in a list called 'clean_chunks' before returning them.\n",
    "#to reiterate: each 'clean_chunks' now contains a clean version of a subtitle text file, but it's divided into 4 parts. \n",
    "def pattern_del(list_):\n",
    "    clean_chunks=[]\n",
    "    #regex pattern for time stamps\n",
    "    time_stamp='\\d+:\\d+\\d+:\\d+,\\d+ --> \\d+:\\d+:\\d+,\\d+'\n",
    "    #for sublist (chunk) in list (chunks)\n",
    "    for x in list_:\n",
    "        index=[]\n",
    "        #indexing for each element in the list\n",
    "        for i in range(len(x)-1):\n",
    "            #formating the regex search according to index\n",
    "            if re.findall('\\d+', x[i]) and re.findall(time_stamp, x[i+1]):\n",
    "                #saving the indexes i (numbering) and i+2 (time stamp) into a list called 'index'\n",
    "                index.append(i)\n",
    "                index.append(i+1)\n",
    "        #converting chunk x into an array\n",
    "        array=np.array(list(x))\n",
    "        #using numpy operation to delete all the elements by their indexes which are present in the 'index' list\n",
    "        new_array = np.delete(array, index)\n",
    "        #converting new cleaned numpy array back to a list before appending to a new list\n",
    "        clean_chunks.append(list(new_array))\n",
    "    return clean_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaecde41-7ee1-4c63-8e3a-28c013e78e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the decompressed srt files\n",
    "path = \"data-20240401T135418Z-001/subtitle decompressed/*.srt\"\n",
    "\n",
    "target_directory = \"data-20240401T135418Z-001/subtitle cleaned/\"\n",
    "os.makedirs(target_directory, exist_ok=True)\n",
    "\n",
    "#iteratively accessing all srt files one by one\n",
    "for filename in glob.glob(path, recursive=True):\n",
    "    #next 3 steps are useful for the last part of this for loop in naming output files.\n",
    "    #removing the path name \n",
    "    filename_ = filename.replace('data-20240401T135418Z-001/subtitle decompressed\\\\','')\n",
    "    with open(filename, 'r', encoding='latin-1') as file:\n",
    "        #read and split the data into a list by *line*\n",
    "        f=file.read().splitlines()\n",
    "        #splitting the list into 4 parts\n",
    "        chunked_sub=chunkin(f)\n",
    "        #removing empty strings from the 4 parts\n",
    "        no_empty_element = half_clean(chunked_sub)\n",
    "        #removing all the time stamps and numberings that come before it to clean all 4 parts.\n",
    "        clean = pattern_del(no_empty_element)\n",
    "        #colapsing the list of lists into one list\n",
    "        full_text = [item for sublist in clean for item in sublist]\n",
    "        #joining the strings/elements into one text string \n",
    "        text_join = '\\n'.join(full_text)\n",
    "        #just for good measure: encoding the data with 'utf-8'\n",
    "        text = text_join.encode('utf-8')\n",
    "        #opening a new text file in a new folder called 'subtitle cleaned' \n",
    "        #the text file will retain the name by its input file (filename_)\n",
    "        with open(target_directory+filename_, \"w\", errors='ignore') as file:\n",
    "            #write the'text' into the text file \n",
    "            file.write(text.decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
